{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"outputs":[],"source":["import csv\n","import os\n","import cv2\n","import numpy as np\n","import pandas as pd\n","import imgaug.augmenters as iaa\n","from sklearn.model_selection import train_test_split, KFold\n","from sklearn.utils import shuffle\n","from sklearn.linear_model import LogisticRegression, LinearRegression\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.svm import SVC\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.model_selection import cross_validate, StratifiedKFold\n","from sklearn import metrics\n","from sklearn.metrics import precision_score, recall_score, f1_score, auc\n","import tensorflow as tf\n","from tensorflow.keras.applications.resnet50 import ResNet50\n","from tensorflow.keras.layers import Dense, Flatten\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.callbacks import EarlyStopping\n","from tensorflow.keras.applications.resnet50 import preprocess_input\n","from keras.utils import to_categorical"]},{"cell_type":"markdown","metadata":{},"source":["### Safe the filenames to the csv file and read it"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# safe the filenames of data to the csv file\n","for split in [\"training\", \"validation\", \"evaluation\"]:\n","    with open(\"/kaggle/working/dataset-1-\" + split +\".csv\", \"w\", newline=\"\") as csvfile:\n","        writer = csv.writer(csvfile)\n","        writer.writerow([\"filename\", \"ground_truth\"])\n","    for food_type, i in zip([\"Egg\", \"Meat\", \"Noodles-Pasta\", \"Rice\", \"Vegetable-Fruit\"], [0, 1, 2, 3, 4]):\n","        filenames = os.listdir(\"/kaggle/input/food11-image-dataset/\"+ split + \"/\" + food_type)\n","        with open(\"/kaggle/working/dataset-1-\" + split +\".csv\", \"a\", newline=\"\") as csvfile:\n","            writer = csv.writer(csvfile)\n","            for filename in filenames:\n","                writer.writerow([food_type +\"/\" + filename, i])\n","\n","# read the csv file\n","train_data = pd.read_csv(f'/kaggle/working/dataset-1-training.csv')\n","valid_data = pd.read_csv(f'/kaggle/working/dataset-1-validation.csv')\n","test_data = pd.read_csv(f'/kaggle/working/dataset-1-evaluation.csv')\n","\n","# shuffle the data \n","train_data = shuffle(train_data)\n","valid_data = shuffle(valid_data)\n","test_data = shuffle(test_data)"]},{"cell_type":"markdown","metadata":{},"source":["### Preprocess the data"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# different amounts of training data\n","# train_data = train_data.sample(frac=0.5)\n","\n","# preprocess the data\n","\n","# data augmentation\n","seq = iaa.Sequential([\n","    iaa.Fliplr(p=0.5), # horizontally flip 50% of all images\n","    iaa.Affine(rotate=(-20, 20), mode='symmetric'), # rotate the images between -20 and 20 degrees, use symmetric padding mode\n","    iaa.Crop(percent=(0, 0.2)), # crop images by 0 to 20% of their height/width\n","])\n","\n","# read the image files\n","x_train = []\n","y_train = []\n","for i, row in train_data.iterrows(): # iterate each row\n","    img = cv2.imread(\"/kaggle/input/food11-image-dataset/training/\" + row['filename'])\n","    img = cv2.resize(img, (100, 100)) # resize the image size\n","#     img = preprocess_input(img) # standardize\n","    x_train.append(img)\n","    y_train.append(row['ground_truth'])\n","    for j in range(5): # generate x augmented images per original image\n","        img_aug = seq(image=img)\n","        img_aug = cv2.resize(img_aug, (100, 100))\n","        x_train.append(img_aug)\n","        y_train.append(row['ground_truth'])\n","x_train = np.array(x_train)\n","y_train = np.array(y_train)\n","print(x_train.shape)\n","\n","x_valid = []\n","y_valid = []\n","for i, row in valid_data.iterrows():\n","    img = cv2.imread(\"/kaggle/input/food11-image-dataset/validation/\" + row['filename'])\n","    img = cv2.resize(img, (100, 100))\n","#     img = preprocess_input(img) # standardize\n","    x_valid.append(img)\n","    y_valid.append(row['ground_truth'])\n","    for j in range(5): # generate x augmented images per original image\n","        img_aug = seq(image=img)\n","        img_aug = cv2.resize(img_aug, (100, 100))\n","        x_valid.append(img_aug)\n","        y_valid.append(row['ground_truth'])\n","x_valid = np.array(x_valid)\n","y_valid = np.array(y_valid)\n","print(x_valid.shape)\n","\n","x_test = []\n","y_test = []\n","for i, row in test_data.iterrows():\n","    img = cv2.imread(\"/kaggle/input/food11-image-dataset/evaluation/\" + row['filename'])\n","    img = cv2.resize(img, (100, 100))\n","#     img = preprocess_input(img) # standardize\n","    x_test.append(img)\n","    y_test.append(row['ground_truth'])\n","x_test = np.array(x_test)\n","y_test = np.array(y_test)\n","print(x_test.shape)"]},{"cell_type":"markdown","metadata":{},"source":["### ResNet"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# convert the labels to one_hot_encoding\n","y_train_one_hot = to_categorical(y_train, num_classes=5)\n","y_valid_one_hot = to_categorical(y_valid, num_classes=5)\n","y_test_one_hot = to_categorical(y_test, num_classes=5)\n","\n","# define the model\n","base_model = ResNet50(weights=\"imagenet\", include_top=False, input_shape=(100, 100, 3))\n","x = base_model.output\n","x = Flatten()(x)\n","x = Dense(256, activation='relu')(x)\n","predictions = Dense(5, activation='softmax')(x)\n","model = Model(inputs=base_model.input, outputs=predictions)\n","\n","# freeze the weight of ResNet50\n","for layer in base_model.layers:\n","    layer.trainable = False\n","\n","# compile the model\n","model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n","\n","model.fit(x_train, y_train_one_hot, validation_data=(x_valid, y_valid_one_hot), epochs=5)\n","print(\"\\n\")\n","\n","# calculate and print the results\n","test_loss, test_acc = model.evaluate(x_test, y_test_one_hot)\n","test_pred = model.predict(x_test)\n","test_pred_classes = np.argmax(test_pred, axis=1)\n","precision = precision_score(y_test, test_pred_classes, average='weighted')\n","recall = recall_score(y_test, test_pred_classes, average='weighted')\n","f1 = f1_score(y_test, test_pred_classes, average='weighted')\n","print(\"\\n\")\n","print(f\"Test accuracy: {test_acc:.3f}\")\n","print(f'Precision: {precision:.3f}')\n","print(f'Recall: {recall:.3f}')\n","print(f'F1 score: {f1:.3f}')"]},{"cell_type":"markdown","metadata":{},"source":["### LogisticRegression, KNN, Decision Tree"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# # logisticRegression model\n","# model = LogisticRegression(penalty='l1', C=0.01, solver='liblinear')\n","\n","# # KNN model\n","# # model = KNeighborsClassifier(n_neighbors=5)\n","\n","# # DesisionTree\n","# # model = DecisionTreeClassifier(max_depth=5, random_state=42)\n","\n","# # train model on all training data\n","# model.fit(x_train, y_train)\n","\n","# # predict test data\n","# y_pred_one_hot = model.predict_proba(x_test)\n","# y_pred = np.argmax(y_pred_one_hot, axis=1)\n","\n","# # calculate accuracy, precision, recall, f1\n","# precision = metrics.precision_score(y_test, y_pred, average='weighted')\n","# recall = metrics.recall_score(y_test, y_pred, average='weighted')\n","# accuracy = metrics.accuracy_score(y_test, y_pred)\n","# f1 = metrics.f1_score(y_test, y_pred, average='weighted')\n","\n","# print(\"Test data:\")\n","# print(f'Accuracy: {accuracy:.3f}')\n","# print(f'Precision: {precision:.3f}')\n","# print(f'Recall: {recall:.3f}')\n","# print(f'F1 Score: {f1:.3f}')"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.8"},"vscode":{"interpreter":{"hash":"b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"}}},"nbformat":4,"nbformat_minor":4}
