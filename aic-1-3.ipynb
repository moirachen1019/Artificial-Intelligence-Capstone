{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"outputs":[],"source":["import csv\n","import os\n","import cv2\n","import numpy as np\n","import pandas as pd\n","import imgaug.augmenters as iaa\n","from sklearn.model_selection import train_test_split, KFold\n","from sklearn.utils import shuffle\n","from sklearn.linear_model import LogisticRegression, LinearRegression\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.svm import SVC\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.model_selection import cross_validate, StratifiedKFold\n","from sklearn import metrics\n","from sklearn.metrics import precision_score, recall_score, f1_score\n","import tensorflow as tf\n","from tensorflow.keras.applications.resnet50 import ResNet50\n","from tensorflow.keras.layers import Dense, Flatten\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.callbacks import EarlyStopping"]},{"cell_type":"markdown","metadata":{},"source":["### Safe the filenames to the csv file and read it"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# safe the filenames of data to the csv file\n","with open(\"dataset_3.csv\", \"w\", newline=\"\") as csvfile:\n","    writer = csv.writer(csvfile)\n","    writer.writerow([\"filename\", \"ground_truth\"])\n","for cat, ans in zip([\"not_my_cat\", \"my_cat\"], [\"0\", \"1\"]):\n","    filenames = os.listdir(\"/Users/chunpei/AIC/HW1/\" + cat + \"/\")\n","    with open(\"dataset_3.csv\", \"a\", newline=\"\") as csvfile:\n","        writer = csv.writer(csvfile)\n","        for filename in filenames:\n","            writer.writerow([cat +\"/\" + filename, ans])\n","\n","# read the csv file\n","data = pd.read_csv(f'/kaggle/input/dataset/dataset_3.csv')\n","\n","# shuffle the data \n","data = shuffle(data)\n","\n","# split the dataset\n","train_data, test_data = train_test_split(data, train_size=0.5, random_state=42)\n","print(train_data.shape)\n","print(test_data.shape)"]},{"cell_type":"markdown","metadata":{},"source":["### Preprocess the data"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# different amounts of training data\n","# train_data = train_data.sample(frac=0.5)\n","\n","# preprocess the data\n","\n","# data augmentation\n","seq = iaa.Sequential([\n","    iaa.Fliplr(p=0.5), # horizontally flip 50% of all images\n","#     iaa.Flipud(p=0.5), # vertically flip 50% of all images\n","    iaa.Affine(rotate=(-20, 20), mode='symmetric'), # rotate the images between -20 and 20 degrees, use symmetric padding mode\n","    iaa.Crop(percent=(0, 0.2)), # crop images by 0 to 20% of their height/width\n","#     iaa.AddToHueAndSaturation(value=(-30, 30)) # change hue and saturation by -30 to 30\n","])\n","\n","# read the image files\n","x_train = []\n","y_train = []\n","for i, row in train_data.iterrows(): # iterate each row\n","    img = cv2.imread(\"/kaggle/input/aic-hw1-3/\" + row['filename'])\n","    img = cv2.resize(img, (100, 100)) # resize the image size\n","    x_train.append(img)\n","    y_train.append(row['ground_truth'])\n","    for j in range(3): # generate x augmented images per original image\n","        img_aug = seq(image=img)\n","        img_aug = cv2.resize(img_aug, (100, 100))\n","        x_train.append(img_aug)\n","        y_train.append(row['ground_truth'])\n","x_train = np.array(x_train)\n","y_train = np.array(y_train)\n","print(x_train.shape)\n","\n","x_test = []\n","y_test = []\n","for i, row in test_data.iterrows():\n","    img = cv2.imread(\"/kaggle/input/aic-hw1-3/\" + row['filename'])\n","    img = cv2.resize(img, (100, 100))\n","    x_test.append(img)\n","    y_test.append(row['ground_truth'])\n","x_test = np.array(x_test)\n","y_test = np.array(y_test)\n","print(x_test.shape)"]},{"cell_type":"markdown","metadata":{},"source":["### ResNet"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# define the model\n","base_model = ResNet50(weights=\"imagenet\", include_top=False, input_shape=(100, 100, 3))\n","x = base_model.output\n","x = Flatten()(x)\n","x = Dense(256, activation='relu')(x)\n","predictions = Dense(1, activation='sigmoid')(x)\n","model = Model(inputs=base_model.input, outputs=predictions)\n","\n","# freeze the weight of ResNet50 \n","for layer in base_model.layers:\n","    layer.trainable = False\n","\n","# compile the model\n","model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n","\n","# define KFold (safe the index of each fold)\n","kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n","train_index_list = []\n","valid_index_list = []\n","for train_index, valid_index in kfold.split(x_train, y_train):\n","    train_index_list.append(train_index)\n","    valid_index_list.append(valid_index)\n","\n","# cross validation\n","for i in range(kfold.get_n_splits()):\n","    print(f\"Fold {i+1}\")\n","    x_train_fold = x_train[train_index_list[i]]\n","    y_train_fold = y_train[train_index_list[i]]\n","    x_valid_fold = x_train[valid_index_list[i]]\n","    y_valid_fold = y_train[valid_index_list[i]]\n","    model.fit(x_train_fold, y_train_fold, validation_data=(x_valid_fold, y_valid_fold), epochs=5)\n","    valid_loss, valid_acc = model.evaluate(x_valid_fold, y_valid_fold)\n","    print(f\"Valid accuracy: {valid_acc}\")\n","    # reset the weights\n","    model.set_weights(model.get_weights())\n","\n","test_loss, test_acc = model.evaluate(x_test, y_test)\n","test_pred = model.predict(x_test)\n","test_pred_classes = (test_pred > 0.5).astype(int)\n","test_precision = precision_score(y_test, test_pred_classes)\n","test_recall = recall_score(y_test, test_pred_classes)\n","test_f1 = f1_score(y_test, test_pred_classes)\n","print(f\"Test accuracy: {test_acc:.3f}\")\n","print(f\"Test precision: {test_precision:.3f}\")\n","print(f\"Test recall: {test_recall:.3f}\")\n","print(f\"Test F1-score: {test_f1:.3f}\")"]},{"cell_type":"markdown","metadata":{},"source":["### LogisticRegression, KNN, SVM, Decision Tree"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# # logisticRegression model\n","# model = LogisticRegression(penalty='l1', C=0.01, solver='liblinear')\n","\n","# # KNN model\n","# # model = KNeighborsClassifier(n_neighbors=5)\n","\n","# # SVM model\n","# # model = SVC(kernel='linear', C=0.01, probability=True)\n","\n","# # DesisionTree\n","# # model = DecisionTreeClassifier(max_depth=5, random_state=42)\n","\n","# # cross validation\n","# cv_results = cross_validate(model, x_train, y_train, cv=5, scoring=['accuracy', 'precision', 'recall', 'f1'])\n","\n","# # print scores\n","# for i in range(5):\n","#     print(f\"Fold {i+1} - accuracy: {cv_results['test_accuracy'][i]:.3f}, Precision: {cv_results['test_precision'][i]:.3f}, Recall: {cv_results['test_recall'][i]:.3f}, F1: {cv_results['test_f1'][i]:.3f}\")\n","# print(f\"\\nValidation: Average accuracy: {cv_results['test_accuracy'].mean():.3f}, Average Precision: {cv_results['test_precision'].mean():.3f}, Average Recall: {cv_results['test_recall'].mean():.3f}, Average F1: {cv_results['test_f1'].mean():.3f}\\n\")\n","\n","# # train model on all training data\n","# model.fit(x_train, y_train)\n","\n","# # predict test data\n","# y_pred = model.predict(x_test)\n","\n","# # calculate and print the results\n","# accuracy = metrics.accuracy_score(y_test, y_pred)\n","# precision = metrics.precision_score(y_test, y_pred, average='weighted')\n","# recall = metrics.recall_score(y_test, y_pred, average='weighted')\n","# f1 = metrics.f1_score(y_test, y_pred, average='weighted')\n","# print(\"Test data:\")\n","# print(f'Accuracy: {accuracy:.3f}')\n","# print(f'Precision: {precision:.3f}')\n","# print(f'Recall: {recall:.3f}')\n","# print(f'F1: {f1:.3f}')"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.8"},"vscode":{"interpreter":{"hash":"b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"}}},"nbformat":4,"nbformat_minor":4}
